{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:02:56.644430Z",
     "start_time": "2023-02-21T17:02:49.770047Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YvGPUQaHhXfL"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "## All CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:35.854352Z",
     "start_time": "2023-02-21T17:02:56.646452Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\PPMI_Data\\Excels\\NonMotors\\Derived250\\Female\\GeneCpG\\LexicalFluency\n",
      "(75, 85923)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentrix</th>\n",
       "      <th>PATNO</th>\n",
       "      <th>Gender</th>\n",
       "      <th>APPRDX</th>\n",
       "      <th>HYS</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeCate</th>\n",
       "      <th>Lexical_Fluency_Category</th>\n",
       "      <th>cg02315971</th>\n",
       "      <th>cg24133836</th>\n",
       "      <th>...</th>\n",
       "      <th>cg12092065</th>\n",
       "      <th>cg10388349</th>\n",
       "      <th>cg11918957</th>\n",
       "      <th>cg26583598</th>\n",
       "      <th>cg11023075</th>\n",
       "      <th>cg02097667</th>\n",
       "      <th>cg21616723</th>\n",
       "      <th>cg27335855</th>\n",
       "      <th>cg18259253</th>\n",
       "      <th>cg15404040</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200973410159_R03C01</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.016106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953091</td>\n",
       "      <td>0.392056</td>\n",
       "      <td>0.913402</td>\n",
       "      <td>0.913637</td>\n",
       "      <td>0.897198</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.913624</td>\n",
       "      <td>0.651860</td>\n",
       "      <td>0.852542</td>\n",
       "      <td>0.909412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200991620021_R03C01</td>\n",
       "      <td>3002</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>67.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025308</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921575</td>\n",
       "      <td>0.416247</td>\n",
       "      <td>0.864819</td>\n",
       "      <td>0.942005</td>\n",
       "      <td>0.907732</td>\n",
       "      <td>0.869391</td>\n",
       "      <td>0.907648</td>\n",
       "      <td>0.834695</td>\n",
       "      <td>0.842573</td>\n",
       "      <td>0.917446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 85923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentrix  PATNO  Gender  APPRDX  HYS   Age  AgeCate  \\\n",
       "0  200973410159_R03C01   3000       2       2    0  69.1        4   \n",
       "1  200991620021_R03C01   3002       2       1    2  67.6        4   \n",
       "\n",
       "   Lexical_Fluency_Category  cg02315971  cg24133836  ...  cg12092065  \\\n",
       "0                         1    0.030109    0.016106  ...    0.953091   \n",
       "1                         1    0.025308    0.017806  ...    0.921575   \n",
       "\n",
       "   cg10388349  cg11918957  cg26583598  cg11023075  cg02097667  cg21616723  \\\n",
       "0    0.392056    0.913402    0.913637    0.897198    0.871237    0.913624   \n",
       "1    0.416247    0.864819    0.942005    0.907732    0.869391    0.907648   \n",
       "\n",
       "   cg27335855  cg18259253  cg15404040  \n",
       "0    0.651860    0.852542    0.909412  \n",
       "1    0.834695    0.842573    0.917446  \n",
       "\n",
       "[2 rows x 85923 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd Z:\\PPMI_Data\\Excels\\NonMotors\\Derived250\\Female\\GeneCpG\\LexicalFluency\n",
    "df = pd.read_csv('LexicalFluencyCateg_Methylome_Female.csv')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:36.216402Z",
     "start_time": "2023-02-21T17:03:35.856386Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPRDX</th>\n",
       "      <th>cg02315971</th>\n",
       "      <th>cg24133836</th>\n",
       "      <th>cg03286969</th>\n",
       "      <th>cg11738782</th>\n",
       "      <th>cg25741731</th>\n",
       "      <th>cg24629744</th>\n",
       "      <th>cg23836745</th>\n",
       "      <th>cg11685489</th>\n",
       "      <th>cg06081147</th>\n",
       "      <th>...</th>\n",
       "      <th>cg12092065</th>\n",
       "      <th>cg10388349</th>\n",
       "      <th>cg11918957</th>\n",
       "      <th>cg26583598</th>\n",
       "      <th>cg11023075</th>\n",
       "      <th>cg02097667</th>\n",
       "      <th>cg21616723</th>\n",
       "      <th>cg27335855</th>\n",
       "      <th>cg18259253</th>\n",
       "      <th>cg15404040</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.016106</td>\n",
       "      <td>0.019371</td>\n",
       "      <td>0.884151</td>\n",
       "      <td>0.026326</td>\n",
       "      <td>0.868373</td>\n",
       "      <td>0.905809</td>\n",
       "      <td>0.825562</td>\n",
       "      <td>0.691096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953091</td>\n",
       "      <td>0.392056</td>\n",
       "      <td>0.913402</td>\n",
       "      <td>0.913637</td>\n",
       "      <td>0.897198</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.913624</td>\n",
       "      <td>0.651860</td>\n",
       "      <td>0.852542</td>\n",
       "      <td>0.909412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025308</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.862173</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>0.906743</td>\n",
       "      <td>0.861073</td>\n",
       "      <td>0.661539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921575</td>\n",
       "      <td>0.416247</td>\n",
       "      <td>0.864819</td>\n",
       "      <td>0.942005</td>\n",
       "      <td>0.907732</td>\n",
       "      <td>0.869391</td>\n",
       "      <td>0.907648</td>\n",
       "      <td>0.834695</td>\n",
       "      <td>0.842573</td>\n",
       "      <td>0.917446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 85916 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPRDX  cg02315971  cg24133836  cg03286969  cg11738782  cg25741731  \\\n",
       "0       2    0.030109    0.016106    0.019371    0.884151    0.026326   \n",
       "1       1    0.025308    0.017806    0.014377    0.862173    0.025717   \n",
       "\n",
       "   cg24629744  cg23836745  cg11685489  cg06081147  ...  cg12092065  \\\n",
       "0    0.868373    0.905809    0.825562    0.691096  ...    0.953091   \n",
       "1    0.888906    0.906743    0.861073    0.661539  ...    0.921575   \n",
       "\n",
       "   cg10388349  cg11918957  cg26583598  cg11023075  cg02097667  cg21616723  \\\n",
       "0    0.392056    0.913402    0.913637    0.897198    0.871237    0.913624   \n",
       "1    0.416247    0.864819    0.942005    0.907732    0.869391    0.907648   \n",
       "\n",
       "   cg27335855  cg18259253  cg15404040  \n",
       "0    0.651860    0.852542    0.909412  \n",
       "1    0.834695    0.842573    0.917446  \n",
       "\n",
       "[2 rows x 85916 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Sentrix','PATNO','HYS','Gender','Lexical_Fluency_Category','Age','AgeCate'], axis=1)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.599260Z",
     "start_time": "2023-02-21T17:03:36.218419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m----> 6\u001b[0m     df2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAPPRDX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     X \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPPRDX\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPPRDX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1423\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[0;32m   1433\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_selection_context():\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1464\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1443\u001b[0m     not_indexed_same: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1464\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:761\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    760\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 761\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    763\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m----> 6\u001b[0m     df2 \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPPRDX\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m     X \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPPRDX\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPPRDX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5446\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m-> 5446\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5447\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   5449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\sample.py:150\u001b[0m, in \u001b[0;36msample\u001b[1;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[0;32m    151\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    152\u001b[0m )\n",
      "File \u001b[1;32mmtrand.pyx:965\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "np.random.seed (1)\n",
    "dframe1 = pd.DataFrame(columns=['Accuracy', 'Std_Dev'])\n",
    "\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    df2 = df1.groupby('APPRDX').apply(lambda x: x.sample(20))\n",
    "    X = df2.drop('APPRDX', axis = 1)\n",
    "    y = df2['APPRDX']\n",
    "    random_forest_model = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = 'gini')\n",
    "    scores = cross_val_score(random_forest_model, X, y, cv = 10, n_jobs = -1)\n",
    "    mean_score = scores.mean()\n",
    "    print(f'Mean accuracy: {mean_score}')\n",
    "    new_row = {'Accuracy': mean_score, 'Std_Dev': std(scores)}\n",
    "    dframe1 = pd.concat([dframe1, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.609311Z",
     "start_time": "2023-02-21T17:03:45.609311Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mean(dframe1['Accuracy']))\n",
    "dframe1.to_csv (\"LexicalFluency_AllCpG_Female_100RF.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "## RanFor 1000 times. Samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.611334Z",
     "start_time": "2023-02-21T17:03:45.611334Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.drop (['APPRDX'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.611334Z",
     "start_time": "2023-02-21T17:03:45.611334Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed (1)\n",
    "dframe1 = pd.DataFrame(columns=['Accuracy', 'Std_Dev'])\n",
    "for i in range (1,101) :\n",
    "        print(i)\n",
    "        df3 = df2.sample(50, axis=1)\n",
    "        df3 = df3.reindex(['APPRDX', *df3.columns], axis=1).assign(APPRDX=df1['APPRDX'])\n",
    "        dataset = df3.groupby('APPRDX').apply(lambda x: x.sample(20))\n",
    "        X = dataset.iloc[:, 1:].values\n",
    "        y = dataset.iloc[:, 0].values\n",
    "        random_forest_model = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = 'gini')\n",
    "        scores = cross_val_score(random_forest_model, X, y, cv = 10, n_jobs = -1)\n",
    "        mean_score = scores.mean()\n",
    "        print(f'Mean accuracy: {mean_score}')\n",
    "        new_row = {'Accuracy': mean_score, 'Std_Dev': std(scores)}\n",
    "        dframe1 = pd.concat([dframe1, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.611334Z",
     "start_time": "2023-02-21T17:03:45.611334Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mean(dframe1['Accuracy']))\n",
    "dframe1.to_csv (\"LexicalFluency_Rand50CpG_Female_100RF.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "## RanFor 100 times. Samples = 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.621400Z",
     "start_time": "2023-02-21T17:03:45.621400Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed (1)\n",
    "dframe1 = pd.DataFrame(columns=['Accuracy', 'Std_Dev'])\n",
    "for i in range (1,101) :\n",
    "        print(i)\n",
    "        df3 = df2.sample(94, axis=1)\n",
    "        df3 = df3.reindex(['APPRDX', *df3.columns], axis=1).assign(APPRDX=df1['APPRDX'])\n",
    "        dataset = df3.groupby('APPRDX').apply(lambda x: x.sample(20))\n",
    "        X = dataset.iloc[:, 1:].values\n",
    "        y = dataset.iloc[:, 0].values\n",
    "        random_forest_model = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = 'gini')\n",
    "        scores = cross_val_score(random_forest_model, X, y, cv = 10, n_jobs = -1)\n",
    "        mean_score = scores.mean()\n",
    "        print(f'Mean accuracy: {mean_score}')\n",
    "        new_row = {'Accuracy': mean_score, 'Std_Dev': std(scores)}\n",
    "        dframe1 = pd.concat([dframe1, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.621400Z",
     "start_time": "2023-02-21T17:03:45.621400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mean(dframe1['Accuracy']))\n",
    "dframe1.to_csv (\"LexicalFluency_Rand94CpG_Female_100RF.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RanFor Top 50 Boruta 100 times. Samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.621400Z",
     "start_time": "2023-02-21T17:03:45.621400Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Top50Boruta_LexicalFluency_Female_Data.csv')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.621400Z",
     "start_time": "2023-02-21T17:03:45.621400Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(['PATNO'], axis=1)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.629421Z",
     "start_time": "2023-02-21T17:03:45.629421Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed (1)\n",
    "dframe1 = pd.DataFrame(columns=['Accuracy', 'Std_Dev'])\n",
    "\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    df2 = df1.groupby('APPRDX').apply(lambda x: x.sample(20))\n",
    "    X = df2.drop('APPRDX', axis = 1)\n",
    "    y = df2['APPRDX']\n",
    "    random_forest_model = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = 'gini')\n",
    "    scores = cross_val_score(random_forest_model, X, y, cv = 10, n_jobs = -1)\n",
    "    mean_score = scores.mean()\n",
    "    print(f'Mean accuracy: {mean_score}')\n",
    "    new_row = {'Accuracy': mean_score, 'Std_Dev': std(scores)}\n",
    "    dframe1 = pd.concat([dframe1, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.631439Z",
     "start_time": "2023-02-21T17:03:45.631439Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mean(dframe1['Accuracy']))\n",
    "dframe1.to_csv (\"LexicalFluency_Boruta50CpG_Female_100RF.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RanFor Top 50 NMI 100 times. Samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.631439Z",
     "start_time": "2023-02-21T17:03:45.631439Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Top50NMI_LexicalFluency_Female_Data.csv')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.631439Z",
     "start_time": "2023-02-21T17:03:45.631439Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(['PATNO'], axis=1)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.631439Z",
     "start_time": "2023-02-21T17:03:45.631439Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed (1)\n",
    "dframe1 = pd.DataFrame(columns=['Accuracy', 'Std_Dev'])\n",
    "\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    df2 = df1.groupby('APPRDX').apply(lambda x: x.sample(20))\n",
    "    X = df2.drop('APPRDX', axis = 1)\n",
    "    y = df2['APPRDX']\n",
    "    random_forest_model = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = 'gini')\n",
    "    scores = cross_val_score(random_forest_model, X, y, cv = 10, n_jobs = -1)\n",
    "    mean_score = scores.mean()\n",
    "    print(f'Mean accuracy: {mean_score}')\n",
    "    new_row = {'Accuracy': mean_score, 'Std_Dev': std(scores)}\n",
    "    dframe1 = pd.concat([dframe1, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.631439Z",
     "start_time": "2023-02-21T17:03:45.631439Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mean(dframe1['Accuracy']))\n",
    "dframe1.to_csv (\"LexicalFluency_NMI50CpG_Female_100RF.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RanFor Top 50 Boruta + NMI 100 times. Samples = 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.639466Z",
     "start_time": "2023-02-21T17:03:45.639466Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('LexicalFluency_Top50sMerge_Data_Female.csv')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.641485Z",
     "start_time": "2023-02-21T17:03:45.641485Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(['PATNO'], axis=1)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.641485Z",
     "start_time": "2023-02-21T17:03:45.641485Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed (1)\n",
    "dframe1 = pd.DataFrame(columns=['Accuracy', 'Std_Dev'])\n",
    "\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    df2 = df1.groupby('APPRDX').apply(lambda x: x.sample(20))\n",
    "    X = df2.drop('APPRDX', axis = 1)\n",
    "    y = df2['APPRDX']\n",
    "    random_forest_model = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = 'gini')\n",
    "    scores = cross_val_score(random_forest_model, X, y, cv = 10, n_jobs = -1)\n",
    "    mean_score = scores.mean()\n",
    "    print(f'Mean accuracy: {mean_score}')\n",
    "    new_row = {'Accuracy': mean_score, 'Std_Dev': std(scores)}\n",
    "    dframe1 = pd.concat([dframe1, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T17:03:45.641485Z",
     "start_time": "2023-02-21T17:03:45.641485Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mean(dframe1['Accuracy']))\n",
    "dframe1.to_csv (\"LexicalFluency_Top50sCpG94_Female_100RF.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPA7K2PAkEFgaKFIvslUMEc",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "random_forest_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
